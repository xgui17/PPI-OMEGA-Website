<!-- ---
layout: default
title: Methods
permalink: /method/
--- -->

<div class="main-content" id="method">
    <h4 id="method-header">Methods</h4>

    <b>游릭 Overview</b>
    <p>
        The <i>PPI-OMEGA</i> framework is designed to enhance protein-protein interaction (PPI) predictions 
        by integrating multi-omics data into a graph-based learning model. We leverage a 
        <b>Variational Graph Autoencoder (VGAE)</b> to capture complex dependencies in PPI networks, using 
        <b>RNA expression</b> and <b>immunohistochemistry (IHC) protein expression</b> as node attributes.
    </p>

    <b>游릭 Dataset & Preprocessing</b>
    <p>
        We constructed our PPI dataset using the <a href="https://string-db.org/cgi/download?sessionId=bPc4lDeKY0hV">STRING database</a>, which contains interaction confidence scores 
        for protein pairs. The dataset was filtered to retain the top 5% high-confidence interactions and 
        mapped to human gene identifiers.
    </p>
    <p>
        Additional multi-omics features were integrated from <a href="https://www.proteinatlas.org/about/download">The Human Protein Atlas</a>:
        <ul>
            <li><b>RNA Expression Data:</b> Processed from 35 tissue types, normalized using TPM values.</li>
            <li><b>IHC Protein Expression Data:</b> Derived from 45 tissues, discretized into 4 bins of different expression levels.</li>
        </ul>
        Principal component analysis (PCA) was conducted separately for normalized RNA expression and protein expression features to reduce dimensionality.
    </p>

    <b>游릭 Graph Construction</b>
    <p>
        Each protein was represented as a node, and edges were formed based on STRING database interactions. 
        Node attributes included:
    </p>
    <ul>
        <li><b>Structural Features:</b> Encoded from known PPI networks.</li>
        <li><b>Node Feature Data:</b> Preprocessed RNA and/or IHC protein values as needed.</li>
    </ul>

    <b>游릭 Variational Graph Autoencoder (VGAE) Model</b>
    <p>
        Our model follows a standard VGAE framework:
        <ul>
            <li><b>Encoder:</b> Two-layer Graph Convolutional Network (GCN) extracts node embeddings.</li>
            <li><b>Latent Space:</b> A probabilistic layer learns a Gaussian distribution for protein representations.</li>
            <li><b>Decoder:</b> Dot product of embeddings reconstructs the adjacency matrix.</li>
        </ul>
    </p>

    <!-- Figure: VGAE Model Architecture -->
    <figure>
        <img src="{{ site.baseurl }}/assets/img/model_architecture.png" alt="VGAE Architecture" width="80%">
        <figcaption><b>Figure 2:</b> Architecture of the Variational Graph Autoencoder (Fan et al., 2020).</figcaption>
    </figure>


    <b>游릭 Hyperparameter Tuning</b>
    <p>
        To optimize model performance, we performed a grid search over key hyperparameters, including the dropout rate, learning rate, and weight decay. Each configuration was evaluated on the validation set, selecting the combination that yielded the highest AUROC and AP scores.
    </p>

    <ul>
        <li><b>Dropout Rate (p):</b> {0.3, 0.4, 0.5}</li>
        <li><b>Learning Rate (풤):</b> {0.001, 0.005, 0.01}</li>
        <li><b>Weight Decay (풭):</b> {5e-4, 1e-3, 5e-3}</li>
    </ul>
    
    <p>
        The best-performing configuration was found to be:
    </p>
    
    <ul>
        <li><b>Dropout Rate:</b> 0.3</li>
        <li><b>Learning Rate:</b> 0.01</li>
        <li><b>Weight Decay:</b> 5e-4</li>
    </ul>
    
    <p>
        This configuration resulted in the highest AUROC (0.9235) and AP (0.9318), significantly improving predictive accuracy compared to suboptimal hyperparameter choices.
    </p>

    <p>
        To ensure robustness, we implemented an early stopping strategy based on validation AUROC. If no improvement of at least 0.01 was observed for 60 consecutive epochs, training was halted to prevent overfitting. Additionally, dropout regularization was applied to mitigate overfitting while ensuring stable convergence.
    </p>
    
    

    <b>游릭 Training & Evaluation</b>

    <p>
        The model is trained using a <b>binary cross-entropy loss</b> with a 
        <b>Kullback-Leibler (KL) divergence</b> regularization term:
        \(\mathcal{L} = \mathcal{L}_{recon} + \beta \mathcal{L}_{KL}\).
        We used the <b>Adam optimizer</b> with a learning rate of 0.001. 
        Training was stopped when validation loss did not improve by a minimum threshold 
        within a set number of epochs.
    </p>

    <b>游릭 Ablation Study</b>

    <p>
        To assess the impact of multi-omics data integration, we conducted an ablation study during which we trained and evaluated the model under 
        four different feature input conditions:
    </p>

    <table>
        <tr>
            <th>Feature Set</th>
            <th>Description</th>
        </tr>
        <tr>
            <td>No Features</td>
            <td>Only the network structure (adjacency matrix) was used as input.</td>
        </tr>
        <tr>
            <td>RNA Only</td>
            <td>RNA expression profiles were included as node attributes.</td>
        </tr>
        <tr>
            <td>Protein Only</td>
            <td>IHC protein expression levels were included as node attributes.</td>
        </tr>
        <tr>
            <td>Combined (RNA + Protein)</td>
            <td>Both RNA expression and IHC protein expression features were integrated.</td>
        </tr>
        <caption><b>Table 1:</b> Description of Different Feature Sets used in Ablation Study</caption>
    </table>

    <p>
        The performance of each model variant was evaluated using <b>AUROC</b> and <b>AP (Average Precision)</b> scores. 
    </p>

    <p><i>Read more about our method architecture and training details on our <a href="https://github.com/xgui17/artifact-directory-PPI-OMEGA/blob/main/report.pdf">report</a>.</i></p>
</div>

<!-- <h4>References</h4>
<ol>
    <li>[1] Smith J., et al. "Graph Neural Networks for PPI Prediction." <i>Bioinformatics</i>, 2022.</li>
    <li>[2] Doe A., et al. "Multi-Omics Integration in PPI Networks." <i>Nature Communications</i>, 2021.</li>
</ol> -->